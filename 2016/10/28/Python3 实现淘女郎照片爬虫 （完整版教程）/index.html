<!doctype html>



  


<html class="theme-next muse use-motion">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  
  
  <link href="/vendors/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/vendors/font-awesome/css/font-awesome.min.css?v=4.4.0" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.0.2" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Hexo, NexT" />





  <link rel="alternate" href="/atom.xml" title="orzangleli" type="application/atom+xml" />




  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.0.2" />






<meta name="description" content="Python3 实现淘女郎照片爬虫 （完整版教程）
一. 项目介绍本项目通过Python 3实现一个爬取淘女郎网页上的美女的头像和详细介绍帖子中的所有图片并下载到本地来。
Todo:1. 将图片自动上传到七牛等云存储空间中2. 将图片的信息添加到在线数据库中
二. 知识点
使用Python 3编程
使用BeautifulSoup解析html网页
使用Selenium抓取动态网页
下载文件的几种方式">
<meta property="og:type" content="article">
<meta property="og:title" content="Python3 实现淘女郎照片爬虫 （完整版教程）">
<meta property="og:url" content="http://www.orzangleli.com/2016/10/28/Python3 实现淘女郎照片爬虫 （完整版教程）/index.html">
<meta property="og:site_name" content="orzangleli">
<meta property="og:description" content="Python3 实现淘女郎照片爬虫 （完整版教程）
一. 项目介绍本项目通过Python 3实现一个爬取淘女郎网页上的美女的头像和详细介绍帖子中的所有图片并下载到本地来。
Todo:1. 将图片自动上传到七牛等云存储空间中2. 将图片的信息添加到在线数据库中
二. 知识点
使用Python 3编程
使用BeautifulSoup解析html网页
使用Selenium抓取动态网页
下载文件的几种方式">
<meta property="og:image" content="http://lxctest.qiniudn.com/2016-10-28_17:45:12_111111.jpg?imageView2/0/w/600">
<meta property="og:image" content="https://dn-anything-about-doc.qbox.me/document-
uid30174labid1970timestamp1470190197607.png/wm">
<meta property="og:image" content="https://dn-anything-about-doc.qbox.me/document-
uid30174labid1970timestamp1470190356134.png/wm">
<meta property="og:image" content="http://i.imgur.com/gtNM6Un.jpg">
<meta property="og:updated_time" content="2016-11-03T11:19:54.879Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Python3 实现淘女郎照片爬虫 （完整版教程）">
<meta name="twitter:description" content="Python3 实现淘女郎照片爬虫 （完整版教程）
一. 项目介绍本项目通过Python 3实现一个爬取淘女郎网页上的美女的头像和详细介绍帖子中的所有图片并下载到本地来。
Todo:1. 将图片自动上传到七牛等云存储空间中2. 将图片的信息添加到在线数据库中
二. 知识点
使用Python 3编程
使用BeautifulSoup解析html网页
使用Selenium抓取动态网页
下载文件的几种方式">
<meta name="twitter:image" content="http://lxctest.qiniudn.com/2016-10-28_17:45:12_111111.jpg?imageView2/0/w/600">



<script type="text/javascript" id="hexo.configuration">
  var NexT = window.NexT || {};
  var CONFIG = {
    scheme: 'Muse',
    sidebar: {"position":"left","display":"post"},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: '0',
      author: '博主'
    }
  };
</script>




  <link rel="canonical" href="http://www.orzangleli.com/2016/10/28/Python3 实现淘女郎照片爬虫 （完整版教程）/"/>


  <title> Python3 实现淘女郎照片爬虫 （完整版教程） | orzangleli </title>
</head>

<body itemscope itemtype="//schema.org/WebPage" lang="zh-Hans">

  








  <div style="display: none;">
    <script src="//s95.cnzz.com/z_stat.php?id=1260851403&web_id=1260851403" language="JavaScript"></script>
  </div>





  
  
    
  

  <div class="container one-collumn sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="//schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">orzangleli</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle">活在梦里的程序员和设计师</p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            首页
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            分类
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            标签
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br />
            
            关于
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="st-search-show-outputs">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />
            
            搜索
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <form class="site-search-form">
  <input type="text" id="st-search-input" class="st-search-input st-default-search-input" />
</form>

<script type="text/javascript">
  (function(w,d,t,u,n,s,e){w['SwiftypeObject']=n;w[n]=w[n]||function(){
    (w[n].q=w[n].q||[]).push(arguments);};s=d.createElement(t);
    e=d.getElementsByTagName(t)[0];s.async=1;s.src=u;e.parentNode.insertBefore(s,e);
  })(window,document,'script','//s.swiftypecdn.com/install/v2/st.js','_st');

  _st('install', '_tMVei7ot2NwU_xzmU_1','2.0.0');
</script>



    </div>
  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="//schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                Python3 实现淘女郎照片爬虫 （完整版教程）
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">发表于</span>
            <time itemprop="dateCreated" datetime="2016-10-28T00:00:00+08:00" content="2016-10-28">
              2016-10-28
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/未分类/" itemprop="url" rel="index">
                    <span itemprop="name">未分类</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2016/10/28/Python3 实现淘女郎照片爬虫 （完整版教程）/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2016/10/28/Python3 实现淘女郎照片爬虫 （完整版教程）/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          
             <span id="/2016/10/28/Python3 实现淘女郎照片爬虫 （完整版教程）/" class="leancloud_visitors" data-flag-title="Python3 实现淘女郎照片爬虫 （完整版教程）">
               &nbsp; | &nbsp;
               <span class="post-meta-item-icon">
                 <i class="fa fa-eye"></i>
               </span>
               <span class="post-meta-item-text">阅读次数 </span>
               <span class="leancloud-visitors-count"></span>
              </span>
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="Python3-实现淘女郎照片爬虫-（完整版教程）"><a href="#Python3-实现淘女郎照片爬虫-（完整版教程）" class="headerlink" title="Python3 实现淘女郎照片爬虫 （完整版教程）"></a>Python3 实现淘女郎照片爬虫 （完整版教程）</h1><hr>
<h2 id="一-项目介绍"><a href="#一-项目介绍" class="headerlink" title="一. 项目介绍"></a>一. 项目介绍</h2><p>本项目通过Python 3实现一个爬取淘女郎网页上的美女的头像和详细介绍帖子中的所有图片并下载到本地来。</p>
<p><strong>Todo:</strong><br>1. 将图片自动上传到七牛等云存储空间中<br>2. 将图片的信息添加到在线数据库中</p>
<h2 id="二-知识点"><a href="#二-知识点" class="headerlink" title="二. 知识点"></a>二. 知识点</h2><ol>
<li>使用Python 3编程</li>
<li>使用BeautifulSoup解析html网页</li>
<li>使用Selenium抓取动态网页</li>
<li>下载文件的几种方式</li>
<li>正则表达式的使用</li>
</ol>
<h2 id="三-项目效果"><a href="#三-项目效果" class="headerlink" title="三. 项目效果"></a>三. 项目效果</h2><p>这是我们要爬取的目标页面：</p>
<p>淘女郎：<a href="https://mm.taobao.com/search_tstar_model.htm" target="_blank" rel="external">https://mm.taobao.com/search_tstar_model.htm</a></p>
<p><strong>目标页面</strong></p>
<p><img src="http://lxctest.qiniudn.com/2016-10-28_17:45:12_111111.jpg?imageView2/0/w/600" alt=""><br><strong>爬取后的本地目录</strong><br><img src="https://dn-anything-about-doc.qbox.me/document-
uid30174labid1970timestamp1470190197607.png/wm" alt="此处输入图片的描述"><br><strong>每个目录中的图片</strong></p>
<p><img src="https://dn-anything-about-doc.qbox.me/document-
uid30174labid1970timestamp1470190356134.png/wm" alt="此处输入图片的描述"></p>
<h2 id="四-项目实战"><a href="#四-项目实战" class="headerlink" title="四. 项目实战"></a>四. 项目实战</h2><h1 id="4-1-安装需要使用的库"><a href="#4-1-安装需要使用的库" class="headerlink" title="4.1 安装需要使用的库"></a>4.1 安装需要使用的库</h1><p>以下是本项目需要使用到的库文件：</p>
<pre><code>from bs4 import BeautifulSoup
import urllib
from selenium import webdriver
import time
import os
import re
import requests
</code></pre><p>需要安装的几个库是bs4，selenium,requests.安装方式是使用pip，分别运行下面的命令：</p>
<pre><code>pip install BeautifulSoup4
pip install selenium
pip install requests
pip install html5lib
</code></pre><p>Selenium<br>是一个强大的网络数据采集工具，最初是为网站自动化测试而开发的。近几年，他还被广泛用于获取精确的网站快照，因为他们可以直接运行在浏览器上。Selenium<br>可以让浏览器自动加载页面，获取需要的数据，甚至页面截屏，或者判断网站上某些动作上是否发生。</p>
<p>Selenium 自己不带浏览器，它需要与第三方浏览器结合在一起使用。我们使用的是PhantomJS浏览器，这是一个无头的浏览器，PhantomJS<br>会把网站加载到内存并执行页面上的 JavaScript，但是不会向用户展示网页的图形化界面，可以用来处理 cookie、JavaScript 及<br>header 信息，以及任何你需要浏览器协助完成的事情。</p>
<p>可以去链接下载，也可以自行搜索下载：</p>
<p>链接：<a href="http://pan.baidu.com/s/1eSLrpzs" target="_blank" rel="external">http://pan.baidu.com/s/1eSLrpzs</a> 密码：vsq9</p>
<h1 id="4-2-项目目标"><a href="#4-2-项目目标" class="headerlink" title="4.2 项目目标"></a>4.2 项目目标</h1><ol>
<li>抓取淘女郎页面中美女的封面，昵称和城市</li>
<li>抓取个人主页中图片</li>
<li>将每个美女的图片以文件夹的形式存储在文件夹中</li>
</ol>
<h1 id="4-3-可行性分析"><a href="#4-3-可行性分析" class="headerlink" title="4.3 可行性分析"></a>4.3 可行性分析</h1><p>淘女郎首页上的源码信息是公开的，本次实验仅仅是用来技术实践，并不带盈利性目的，也不将图片用于其他商业环境，并不会产生商业上的产权纠纷，所以这个项目是可行的。</p>
<h1 id="4-4-流程说明"><a href="#4-4-流程说明" class="headerlink" title="4.4 流程说明"></a>4.4 流程说明</h1><p>通过 Selenium Webdriver 获得目标页面源码，之后通过 BeautifulSoup<br>解析概源码，通过正则表达式提取出模特名字、所在城市、身高、体重，个人主页、封面图片地址等信息，根据模特名字和城市建立文件夹。</p>
<p>再次通过 Selenium Webdriver 获得模特个人主页的页面源码，之后通过 BeautifulSoup<br>解析源码，通过正则获得页面艺术照的URL地址信息。</p>
<p>最后通过 urllib 内置库，打开图片地址，通过二进制读写的方式获得模特艺术照，并将艺术照存在相应文件夹里面。</p>
<h1 id="4-5-网页源码分析"><a href="#4-5-网页源码分析" class="headerlink" title="4.5 网页源码分析"></a>4.5 网页源码分析</h1><p><img src="http://i.imgur.com/gtNM6Un.jpg" alt=""></p>
<p>图中的1,2,3,4分别代表该MM的个人介绍主页地址，封面图片地址，名字和城市，身高体重。第四个我们不使用，只需要获取前三个信息即可。进入个人主页，我们继续类似前面的审查元素，可以看到</p>
<pre><code>&lt;img style=&quot;width: 630.0px;float: none;margin: 10.0px;height: 945.0px;&quot; width=&quot;630&quot; height=&quot;945&quot; src=&quot;//img.alicdn.com/imgextra/i2/927018118/TB1vpJVNVXXXXXzaXXXXXXXXXXX_!!0-tstar.jpg&quot;&gt;
</code></pre><p>里面的图片的标签都是img，而且图片的网址前面是一样的，因此可以使用正则表达式来匹配图片地址：</p>
<pre><code>^\/\/img\.alicdn\.com\/imgextra\/.*\.jpg$
</code></pre><p>这样可以过滤掉其他图片。</p>
<h1 id="4-6-程序实战"><a href="#4-6-程序实战" class="headerlink" title="4.6 程序实战"></a>4.6 程序实战</h1><p>首先导入要使用的库</p>
<pre><code>from bs4 import BeautifulSoup
import urllib
from selenium import webdriver
import time
import os
import re
import requests
</code></pre><p>建一个类，叫做Taonvlang,里面有几个函数：</p>
<p>get_detail_imgs(self,detail_url,dir_name): 根据detail_url获取个人主页图片，并存到目录dir_name中</p>
<p>get_all_data(self): 获取主页的所有的美女封面和个人主页</p>
<p><strong>init</strong>(self,driver,homePage,outputDir): 初始化函数，初始化类中变量</p>
<p>具体查看代码</p>
<pre><code>from bs4 import BeautifulSoup
import urllib
from selenium import webdriver
import time
import os
import re
import requests

class Taolvlang(object):
    def __init__(self,driver,homePage,outputDir):
        self.driver = driver
        self.homePage = homePage
        self.outputDir = outputDir

    def get_detail_imgs(self,detail_url,dir_name):
        num = 0    #计数器，用于统计页面上的图片，作为图片名字
        self.driver.get(detail_url)  #访问个人主页
        js=&quot;var q=document.documentElement.scrollTop=10000&quot;
        self.driver.execute_script(js)    #执行JS脚本，这个脚本主要是滚动页面到最下面，
        #因为有些网页是动态加载的，用户滑动到哪里加载到哪里
        bs = BeautifulSoup(driver.page_source,&quot;html5lib&quot;)   #使用BeautifulSoup解析网页源码，使用的是html5lib,如果不安装这个库，会报错
        allImage = bs.findAll(&quot;img&quot;,{&quot;src&quot;:re.compile(&quot;^\/\/img\.alicdn\.com\/imgextra\/.*.jpg$&quot;)}) #使用正则表达式匹配所有图片 
        for image in allImage:
            img_url = image[&quot;src&quot;]    #获取图片的src
            if not img_url.startswith(&quot;http:&quot;): 
                img_url = &quot;http:&quot;+img_url    #给图片地址加上http：
            num = num +1    #计数器+1
            r = requests.get(img_url)   #使用requests获取图片
            if not os.path.exists(&quot;%s/%d.jpg&quot;%(dir_name,num)):    #判断是否已经存在这个文件了
                with open(&quot;%s/%d.jpg&quot;%(dir_name,num),&quot;wb&quot;) as pic:
                    pic.write(r.content)    #不存在的话就保存到文件中

    def get_all_data(self):  
        self.driver.get(homePage)   #访问主页
        js=&quot;var q=document.documentElement.scrollTop=10000&quot;
        self.driver.execute_script(js)
        time.sleep(3)    #等待网页加载完成
        self.driver.get_screenshot_as_file(&quot;1.jpg&quot;)    #保存网页截图
        bs = BeautifulSoup(self.driver.page_source,&quot;html5lib&quot;)    #使用BeautifulSoup解析网页源码，使用的是html5lib,如果不安装这个库，会报错
        allItem = bs.findAll(class_=&quot;item&quot;)   #找到所有的项，是class 为item的
        for item in allItem:
            detail_url = item.find(class_=&quot;item-link&quot;)[&quot;href&quot;]  #获取个人主页连接
            header_img_url = item.find(&quot;img&quot;)[&quot;src&quot;]   #获取封面图片链接
            dir_name = outputDir+&quot;%s_%s&quot;%(item.find(class_=&quot;name&quot;).get_text(),item.find(class_=&quot;city&quot;).get_text())   #获取名字和城市名组成文件夹名字
            if not os.path.exists(dir_name):   #如果文件夹不存在新建
                os.makedirs(dir_name)
            if not detail_url.startswith(&quot;http:&quot;):
                detail_url = &quot;http:&quot;+detail_url
            if not header_img_url.startswith(&quot;http:&quot;):
                header_img_url = &quot;http:&quot;+header_img_url
            print(&quot;detail_url=%s&quot;%detail_url)
            print(&quot;header_img_url=%s&quot;%header_img_url)
            #将头像存入目录
            if not os.path.exists(outputDir+&quot;%s/0.jpg&quot;%dir_name):
                urllib.request.urlretrieve(header_img_url,outputDir+&quot;%s/0.jpg&quot;%dir_name)
            #获取详细帖子中的照片
            self.get_detail_imgs(detail_url,dir_name)


#本地浏览器路径        
browserPath = &quot;phantomjs.exe&quot;
#主页路径
homePage = &apos;https://mm.taobao.com/search_tstar_model.htm?&apos;
#输出目录
outputDir = &quot;/photos/&quot;   
driver = webdriver.PhantomJS(executable_path = browserPath)
#实例化类，执行获取数据
taoObj = Taolvlang(driver,homePage,outputDir)
taoObj.get_all_data()
</code></pre><h2 id="五-项目地址"><a href="#五-项目地址" class="headerlink" title="五.项目地址"></a>五.项目地址</h2><p><a href="https://github.com/hust201010701/TaonvlangCrawler" target="_blank" rel="external">https://github.com/hust201010701/TaonvlangCrawler</a></p>
<p>欢迎大家Star.</p>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        
  <div style="padding: 10px 0; margin: 20px auto; width: 90%; text-align: center;">
    <div>如果你觉得本文帮助了你，你可以选择打赏支持我继续创作。</div>
    <button id="rewardButton" disable="enable" onclick="var qr = document.getElementById('QR'); if (qr.style.display === 'none') {qr.style.display='block';} else {qr.style.display='none'}">
      <span>赏</span>
    </button>
    <div id="QR" style="display: none;">
      
        <div id="wechat" style="display: inline-block">
          <img id="wechat_qr" src="/assets/weixin.png" alt="orzangleli WeChat Pay"/>
          <p>微信打赏</p>
        </div>
      
      
        <div id="alipay" style="display: inline-block">
          <img id="alipay_qr" src="/assets/zhifubao.png" alt="orzangleli Alipay"/>
          <p>支付宝打赏</p>
        </div>
      
    </div>
  </div>


      
    </div>

    <footer class="post-footer">
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2016/10/21/Python 3.5的环境下使用opencv 3.1版本/" rel="next" title="Python 3.5的环境下使用opencv 3.1版本">
                <i class="fa fa-chevron-left"></i> Python 3.5的环境下使用opencv 3.1版本
              </a>
            
          </div>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2016/10/30/Windows 平台下的整站抓取工具  WinHTTrack Website Copier 使用/" rel="prev" title="Windows 平台下的整站抓取工具  WinHTTrack Website Copier 使用">
                Windows 平台下的整站抓取工具  WinHTTrack Website Copier 使用 <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
        <div class="ds-share flat" data-thread-key="2016/10/28/Python3 实现淘女郎照片爬虫 （完整版教程）/"
     data-title="Python3 实现淘女郎照片爬虫 （完整版教程）"
     data-content=""
     data-url="http://www.orzangleli.com/2016/10/28/Python3 实现淘女郎照片爬虫 （完整版教程）/">
  <div class="ds-share-inline">
    <ul  class="ds-share-icons-16">

      <li data-toggle="ds-share-icons-more"><a class="ds-more" href="javascript:void(0);">分享到：</a></li>
      <li><a class="ds-weibo" href="javascript:void(0);" data-service="weibo">微博</a></li>
      <li><a class="ds-qzone" href="javascript:void(0);" data-service="qzone">QQ空间</a></li>
      <li><a class="ds-qqt" href="javascript:void(0);" data-service="qqt">腾讯微博</a></li>
      <li><a class="ds-wechat" href="javascript:void(0);" data-service="wechat">微信</a></li>

    </ul>
    <div class="ds-share-icons-more">
    </div>
  </div>
</div>
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
      <div class="ds-thread" data-thread-key="2016/10/28/Python3 实现淘女郎照片爬虫 （完整版教程）/"
           data-title="Python3 实现淘女郎照片爬虫 （完整版教程）" data-url="http://www.orzangleli.com/2016/10/28/Python3 实现淘女郎照片爬虫 （完整版教程）/">
      </div>
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel ">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="//schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/avatar.gif"
               alt="orzangleli" />
          <p class="site-author-name" itemprop="name">orzangleli</p>
          <p class="site-description motion-element" itemprop="description">华中科技大学 本科10级 硕士14级 一个热爱技术的宅~</p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/">
              <span class="site-state-item-count">65</span>
              <span class="site-state-item-name">日志</span>
            </a>
          </div>

          
            <div class="site-state-item site-state-categories">
              <a href="/categories">
                <span class="site-state-item-count">13</span>
                <span class="site-state-item-name">分类</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">17</span>
                <span class="site-state-item-name">标签</span>
              </a>
            </div>
          

        </nav>

        
          <div class="feed-link motion-element">
            <a href="/atom.xml" rel="alternate">
              <i class="fa fa-rss"></i>
              RSS
            </a>
          </div>
        

        <div class="links-of-author motion-element">
          
        </div>

        
        

        
        

      </section>

      
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">
            
              
            
            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Python3-实现淘女郎照片爬虫-（完整版教程）"><span class="nav-number">1.</span> <span class="nav-text">Python3 实现淘女郎照片爬虫 （完整版教程）</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#一-项目介绍"><span class="nav-number">1.1.</span> <span class="nav-text">一. 项目介绍</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#二-知识点"><span class="nav-number">1.2.</span> <span class="nav-text">二. 知识点</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#三-项目效果"><span class="nav-number">1.3.</span> <span class="nav-text">三. 项目效果</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#四-项目实战"><span class="nav-number">1.4.</span> <span class="nav-text">四. 项目实战</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#4-1-安装需要使用的库"><span class="nav-number">2.</span> <span class="nav-text">4.1 安装需要使用的库</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#4-2-项目目标"><span class="nav-number">3.</span> <span class="nav-text">4.2 项目目标</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#4-3-可行性分析"><span class="nav-number">4.</span> <span class="nav-text">4.3 可行性分析</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#4-4-流程说明"><span class="nav-number">5.</span> <span class="nav-text">4.4 流程说明</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#4-5-网页源码分析"><span class="nav-number">6.</span> <span class="nav-text">4.5 网页源码分析</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#4-6-程序实战"><span class="nav-number">7.</span> <span class="nav-text">4.6 程序实战</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#五-项目地址"><span class="nav-number">7.1.</span> <span class="nav-text">五.项目地址</span></a></li></ol></li></ol></div>
            
          </div>
        </section>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright" >
  
  &copy; 
  <span itemprop="copyrightYear">2017</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">orzangleli</span>
</div>

<div class="powered-by">
  由 <a class="theme-link" href="https://hexo.io">Hexo</a> 强力驱动
</div>

<div class="theme-info">
  主题 -
  <a class="theme-link" href="https://github.com/iissnan/hexo-theme-next">
    NexT.Muse
  </a>
</div>

        

        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  



  
  <script type="text/javascript" src="/vendors/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/vendors/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/vendors/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/vendors/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.0.2"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.0.2"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.0.2"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.0.2"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.0.2"></script>



  

  
    
  

  <script type="text/javascript">
    var duoshuoQuery = {short_name:"orzangleli"};
    (function() {
      var ds = document.createElement('script');
      ds.type = 'text/javascript';ds.async = true;
      ds.id = 'duoshuo-script';
      ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
      ds.charset = 'UTF-8';
      (document.getElementsByTagName('head')[0]
      || document.getElementsByTagName('body')[0]).appendChild(ds);
    })();
  </script>

  
    
    <script src="/vendors/ua-parser-js/dist/ua-parser.min.js?v=0.7.9"></script>
    <script src="/js/src/hook-duoshuo.js"></script>
  






  
  
  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length == 0) {
       search_path = "search.xml";
    }
    var path = "/" + search_path;
    // monitor main search box;

    function proceedsearch() {
      $("body").append('<div class="popoverlay">').css('overflow', 'hidden');
      $('.popup').toggle();

    }
    // search function;
    var searchFunc = function(path, search_id, content_id) {
    'use strict';
    $.ajax({
        url: path,
        dataType: "xml",
        async: true,
        success: function( xmlResponse ) {
            // get the contents from search data
            isfetched = true;
            $('.popup').detach().appendTo('.header-inner');
            var datas = $( "entry", xmlResponse ).map(function() {
                return {
                    title: $( "title", this ).text(),
                    content: $("content",this).text(),
                    url: $( "url" , this).text()
                };
            }).get();
            var $input = document.getElementById(search_id);
            var $resultContent = document.getElementById(content_id);
            $input.addEventListener('input', function(){
                var matchcounts = 0;
                var str='<ul class=\"search-result-list\">';
                var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                $resultContent.innerHTML = "";
                if (this.value.trim().length > 1) {
                // perform local searching
                datas.forEach(function(data) {
                    var isMatch = false;
                    var content_index = [];
                    var data_title = data.title.trim().toLowerCase();
                    var data_content = data.content.trim().replace(/<[^>]+>/g,"").toLowerCase();
                    var data_url = decodeURIComponent(data.url);
                    var index_title = -1;
                    var index_content = -1;
                    var first_occur = -1;
                    // only match artiles with not empty titles and contents
                    if(data_title != '') {
                        keywords.forEach(function(keyword, i) {
                            index_title = data_title.indexOf(keyword);
                            index_content = data_content.indexOf(keyword);
                            if( index_title >= 0 || index_content >= 0 ){
                                isMatch = true;
								if (i == 0) {
                                    first_occur = index_content;
                                }
                            } 
							
                        });
                    }
                    // show search results
                    if (isMatch) {
                        matchcounts += 1;
                        str += "<li><a href='"+ data_url +"' class='search-result-title'>"+ data_title +"</a>";
                        var content = data.content.trim().replace(/<[^>]+>/g,"");
                        if (first_occur >= 0) {
                            // cut out 100 characters
                            var start = first_occur - 20;
                            var end = first_occur + 80;
                            if(start < 0){
                                start = 0;
                            }
                            if(start == 0){
                                end = 50;
                            }
                            if(end > content.length){
                                end = content.length;
                            }
                            var match_content = content.substring(start, end);
                            // highlight all keywords
                            keywords.forEach(function(keyword){
                                var regS = new RegExp(keyword, "gi");
                                match_content = match_content.replace(regS, "<b class=\"search-keyword\">"+keyword+"</b>");
                            });

                            str += "<p class=\"search-result\">" + match_content +"...</p>"
                        }
                        str += "</li>";
                    }
                })};
                str += "</ul>";
                if (matchcounts == 0) { str = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>' }
                if (keywords == "") { str = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>' }
                $resultContent.innerHTML = str;
            });
            proceedsearch();
        }
    });}

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched == false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };

    });

    $('.popup-btn-close').click(function(e){
      $('.popup').hide();
      $(".popoverlay").remove();
      $('body').css('overflow', '');
    });
    $('.popup').click(function(e){
      e.stopPropagation();
    });
  </script>


  

  

  
  <script src="https://cdn1.lncld.net/static/js/av-core-mini-0.6.1.js"></script>
  <script>AV.initialize("OFpzcYRP2UGNTzmwtFryQx9z-gzGzoHsz", "qEsNfoXB9uWjx6T6WnpIm78U");</script>
  <script>
    function showTime(Counter) {
      var query = new AV.Query(Counter);
      var entries = [];
      var $visitors = $(".leancloud_visitors");

      $visitors.each(function () {
        entries.push( $(this).attr("id").trim() );
      });

      query.containedIn('url', entries);
      query.find()
        .done(function (results) {
          var COUNT_CONTAINER_REF = '.leancloud-visitors-count';

          if (results.length === 0) {
            $visitors.find(COUNT_CONTAINER_REF).text(0);
            return;
          }

          for (var i = 0; i < results.length; i++) {
            var item = results[i];
            var url = item.get('url');
            var time = item.get('time');
            var element = document.getElementById(url);

            $(element).find(COUNT_CONTAINER_REF).text(time);
          }
          for(var i = 0; i < entries.length; i++) {
            var url = entries[i];
            var element = document.getElementById(url);
            var countSpan = $(element).find(COUNT_CONTAINER_REF);
            if( countSpan.text() == '') {
              countSpan.text(0);
            }
          }
        })
        .fail(function (object, error) {
          console.log("Error: " + error.code + " " + error.message);
        });
    }

    function addCount(Counter) {
      var $visitors = $(".leancloud_visitors");
      var url = $visitors.attr('id').trim();
      var title = $visitors.attr('data-flag-title').trim();
      var query = new AV.Query(Counter);

      query.equalTo("url", url);
      query.find({
        success: function(results) {
          if (results.length > 0) {
            var counter = results[0];
            counter.fetchWhenSave(true);
            counter.increment("time");
            counter.save(null, {
              success: function(counter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(counter.get('time'));
              },
              error: function(counter, error) {
                console.log('Failed to save Visitor num, with error message: ' + error.message);
              }
            });
          } else {
            var newcounter = new Counter();
            /* Set ACL */
            var acl = new AV.ACL();
            acl.setPublicReadAccess(true);
            acl.setPublicWriteAccess(true);
            newcounter.setACL(acl);
            /* End Set ACL */
            newcounter.set("title", title);
            newcounter.set("url", url);
            newcounter.set("time", 1);
            newcounter.save(null, {
              success: function(newcounter) {
                var $element = $(document.getElementById(url));
                $element.find('.leancloud-visitors-count').text(newcounter.get('time'));
              },
              error: function(newcounter, error) {
                console.log('Failed to create');
              }
            });
          }
        },
        error: function(error) {
          console.log('Error:' + error.code + " " + error.message);
        }
      });
    }

    $(function() {
      var Counter = AV.Object.extend("Counter");
      if ($('.leancloud_visitors').length == 1) {
        addCount(Counter);
      } else if ($('.post-title-link').length > 1) {
        showTime(Counter);
      }
    });
  </script>



  

  


</body>
</html>
